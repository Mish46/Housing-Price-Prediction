{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8817428,"sourceType":"datasetVersion","datasetId":5304336}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear alg\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport copy\nimport math\n\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-30T06:07:52.035546Z","iopub.execute_input":"2024-06-30T06:07:52.035953Z","iopub.status.idle":"2024-06-30T06:07:52.055767Z","shell.execute_reply.started":"2024-06-30T06:07:52.035913Z","shell.execute_reply":"2024-06-30T06:07:52.054519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#importing the data\ntest=pd.read_csv(\"/kaggle/input/new-dataset/test.csv\")\ntrain=pd.read_csv(\"/kaggle/input/new-dataset/train.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-06-30T06:07:52.058235Z","iopub.execute_input":"2024-06-30T06:07:52.058701Z","iopub.status.idle":"2024-06-30T06:07:52.111433Z","shell.execute_reply.started":"2024-06-30T06:07:52.058659Z","shell.execute_reply":"2024-06-30T06:07:52.110167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Viewing train data\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-30T06:07:52.112923Z","iopub.execute_input":"2024-06-30T06:07:52.113396Z","iopub.status.idle":"2024-06-30T06:07:52.137917Z","shell.execute_reply.started":"2024-06-30T06:07:52.113353Z","shell.execute_reply":"2024-06-30T06:07:52.136600Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Viewing test data\ntest.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-30T06:07:52.139132Z","iopub.execute_input":"2024-06-30T06:07:52.139554Z","iopub.status.idle":"2024-06-30T06:07:52.166057Z","shell.execute_reply.started":"2024-06-30T06:07:52.139523Z","shell.execute_reply":"2024-06-30T06:07:52.164755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Checking for the number of missing values in the train data\n# Creates a new DataFrame 'train_df' from the dictionary 'train_df'\ntrain_df = pd.DataFrame(train)\n# Calculate missing values by summing up the number of NaN values in each column\nmissing_values = train_df.isnull().sum()\n\n\n# Plotting\nplt.figure(figsize=(10, 6))  # Set the figure size to 10x6 inches\nplt.bar(missing_values.index, missing_values.values, color='skyblue')  # Create a bar plot\nplt.xlabel('Columns')  # Label for the x-axis\nplt.ylabel('Number of Missing Values')  # Label for the y-axis\nplt.title('Missing Values in Dataset')  # Title of the plot\nplt.xticks(rotation=45)  # Rotate x-axis labels by 45 degrees for better readability\nplt.tight_layout()  # Adjust subplot parameters to give specified padding\nplt.show()  # Display the plot","metadata":{"execution":{"iopub.status.busy":"2024-06-30T06:07:52.168556Z","iopub.execute_input":"2024-06-30T06:07:52.168901Z","iopub.status.idle":"2024-06-30T06:07:53.132554Z","shell.execute_reply.started":"2024-06-30T06:07:52.168874Z","shell.execute_reply":"2024-06-30T06:07:53.131264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Checking for the number of missing values in the test data\n# Creates a new DataFrame 'test_df' from the dictionary 'test_df'\ntest_df = pd.DataFrame(test)\n# Calculate missing values by summing up the number of NaN values in each column\nmissing_values = test_df.isnull().sum()\n\n\n# Plotting\nplt.figure(figsize=(10, 6))  # Set the figure size to 10x6 inches\nplt.bar(missing_values.index, missing_values.values, color='skyblue')  # Create a bar plot\nplt.xlabel('Columns')  # Label for the x-axis\nplt.ylabel('Number of Missing Values')  # Label for the y-axis\nplt.title('Missing Values in Dataset')  # Title of the plot\nplt.xticks(rotation=45)  # Rotate x-axis labels by 45 degrees for better readability\nplt.tight_layout()  # Adjust subplot parameters to give specified padding\nplt.show()  # Display the plot","metadata":{"execution":{"iopub.status.busy":"2024-06-30T06:07:53.134081Z","iopub.execute_input":"2024-06-30T06:07:53.134455Z","iopub.status.idle":"2024-06-30T06:07:54.061682Z","shell.execute_reply.started":"2024-06-30T06:07:53.134424Z","shell.execute_reply":"2024-06-30T06:07:54.060083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#One Hot encoding for Categorical Variables\n# Identify categorical columns\ncategorical_cols = train_df.select_dtypes(include=['object']).columns\n\n# One-hot encoding for categorical variables\ntrain_df= pd.get_dummies(train_df, columns=categorical_cols, drop_first=True)\ntest_df= pd.get_dummies(test_df, columns=categorical_cols, drop_first=True)\n\n# Align test set with training set columns\ntrain_df,test_df=train_df.align(test_df, join='outer', axis=1, fill_value=0)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-30T06:07:54.064806Z","iopub.execute_input":"2024-06-30T06:07:54.065980Z","iopub.status.idle":"2024-06-30T06:07:54.176293Z","shell.execute_reply.started":"2024-06-30T06:07:54.065926Z","shell.execute_reply":"2024-06-30T06:07:54.175120Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Cleaning the train and test data by removing 'Nan' and 'Missing values'(Numerical)\ntrain_mean_values = train_df.mean()  # Calculate mean for each column\ntest_mean_values = test_df.mean()\n\ntrain_df.fillna(train_df.mean(), inplace=True)  # Replace NaNs in training data with mean\ntest_df.fillna(test_df.mean(), inplace=True)   # Replace NaNs in test data with mean ","metadata":{"execution":{"iopub.status.busy":"2024-06-30T06:07:54.178346Z","iopub.execute_input":"2024-06-30T06:07:54.179468Z","iopub.status.idle":"2024-06-30T06:07:54.364933Z","shell.execute_reply.started":"2024-06-30T06:07:54.179434Z","shell.execute_reply":"2024-06-30T06:07:54.363743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Seperating the data into X and Y\nX=train_df.drop(columns=['SalePrice'])\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nX= scaler.fit_transform(X)\nY=train_df['SalePrice']\n","metadata":{"execution":{"iopub.status.busy":"2024-06-30T06:07:54.366452Z","iopub.execute_input":"2024-06-30T06:07:54.366815Z","iopub.status.idle":"2024-06-30T06:07:54.403411Z","shell.execute_reply.started":"2024-06-30T06:07:54.366785Z","shell.execute_reply":"2024-06-30T06:07:54.402277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Initializing Random Weights and Bias\nnum_columns =X.shape[1]\nw = np.random.rand(num_columns)\nb = np.random.rand()\n\n#The cost function\ndef costf(X, Y, w, b):\n    m = X.shape[0]\n    f_wb = np.dot(X, w) + b\n    squared_error = np.sum((f_wb - Y) ** 2)\n    cost = squared_error / (2 * m)\n    return cost\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-06-30T06:07:54.404947Z","iopub.execute_input":"2024-06-30T06:07:54.405313Z","iopub.status.idle":"2024-06-30T06:07:54.412414Z","shell.execute_reply.started":"2024-06-30T06:07:54.405284Z","shell.execute_reply":"2024-06-30T06:07:54.411257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def compute_gradient(X, Y, w, b):\n    m = X.shape[0]\n    n = X.shape[1]\n    dj_dw = np.zeros(n)\n    dj_db = 0.0\n\n\n\n    for i in range(m):\n        f_wb_i = np.dot(X[i], w) + b  # Ensure correct dot product\n        err = f_wb_i - Y.iloc[i]  # Access Y value for row i\n        dj_dw += err * X[i]\n        dj_db += err\n\n    dj_dw /= m\n    dj_db /= m\n\n    return dj_dw, dj_db\n","metadata":{"execution":{"iopub.status.busy":"2024-06-30T06:07:54.413663Z","iopub.execute_input":"2024-06-30T06:07:54.414026Z","iopub.status.idle":"2024-06-30T06:07:54.428308Z","shell.execute_reply.started":"2024-06-30T06:07:54.413997Z","shell.execute_reply":"2024-06-30T06:07:54.427070Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import math\n\ndef gradient_descent(X, Y, w_in, b_in, cost_function, gradient_function, alpha, num_iters):\n    J_history = []\n    w = np.copy(w_in)\n    b = b_in\n\n    m = X.shape[0]\n\n    for i in range(num_iters):\n        dj_dw, dj_db = gradient_function(X, Y, w, b)\n\n        w -= alpha * dj_dw\n        b -= alpha * dj_db\n\n        # Compute cost and store in history\n        cost = cost_function(X, Y, w, b)\n        J_history.append(cost)\n\n        # Print cost every 100 iterations or at specified intervals\n        if i % math.ceil(num_iters / 10) == 0:\n            print(f\"Iteration {i:4d}: Cost {cost:8.2f}\")\n\n    return w, b, J_history\n","metadata":{"execution":{"iopub.status.busy":"2024-06-30T06:07:54.431462Z","iopub.execute_input":"2024-06-30T06:07:54.432131Z","iopub.status.idle":"2024-06-30T06:07:54.441354Z","shell.execute_reply.started":"2024-06-30T06:07:54.432085Z","shell.execute_reply":"2024-06-30T06:07:54.439868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assuming X and Y are already defined\nnum_features = X.shape[1]\ninitial_w = np.random.rand(num_features)\ninitial_b = np.random.rand()\n\nalpha = 0.015\niterations = 100\n\n# Run gradient descent\nw_final, b_final, J_hist = gradient_descent(X, Y, initial_w, initial_b, costf, compute_gradient, alpha, iterations)\n\nprint(f\"b,w found by gradient descent: {b_final:0.2f},{w_final} \")\n\nfor i in range(5):\n    print(f\"prediction: {np.dot(X[i], w_final) + b_final:0.2f}, target value: {Y.iloc[i]}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-06-30T06:07:54.442930Z","iopub.execute_input":"2024-06-30T06:07:54.443360Z","iopub.status.idle":"2024-06-30T06:07:58.284086Z","shell.execute_reply.started":"2024-06-30T06:07:54.443326Z","shell.execute_reply":"2024-06-30T06:07:58.282736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(test_df, w_final, b_final, scaler):\n    # Standardize test data using the same scaler as used for training\n    X_test = test_df.drop(columns=['SalePrice'])\n    X_test = scaler.transform(X_test)\n    \n    # Predict using the trained weights and bias\n    predictions = np.dot(X_test, w_final) + b_final\n    \n    return predictions\n\ntest_ids = test_df['Id']\npredictions=predict(test_df, w_final, b_final, scaler)\n\nsubmission_df = pd.DataFrame({\n    'Id':test_ids,\n    'SalePrice': predictions\n})\n\n# Save the DataFrame to a CSV file (adjust the filename as needed)\nsubmission_df.to_csv('submission.csv', index=False)\n\nprint(\"Submission file 'submission.csv' created successfully.\")","metadata":{"execution":{"iopub.status.busy":"2024-06-30T06:07:58.285884Z","iopub.execute_input":"2024-06-30T06:07:58.297622Z","iopub.status.idle":"2024-06-30T06:07:58.354394Z","shell.execute_reply.started":"2024-06-30T06:07:58.297554Z","shell.execute_reply":"2024-06-30T06:07:58.352753Z"},"trusted":true},"execution_count":null,"outputs":[]}]}